{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio con SpeechRecognition\n",
        "\n",
        "Realizar por medio de un .wav un SpeechRecognition\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Yj7Z7iAzUc_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalacion global en colab\n",
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wCJjXQXDL0xZ",
        "outputId": "e02d49ad-4952-44ad-e5b2-88ef6179ff32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.13.2)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xrc5oXMGJ32N"
      },
      "outputs": [],
      "source": [
        "# Importando librerias\n",
        "import speech_recognition as sr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la instancia\n",
        "r = sr.Recognizer()"
      ],
      "metadata": {
        "id": "DRNuk_EeKA7o"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trabajando con el fichero de audio\n",
        "\n",
        "Para este caso usaremos un .wav\n",
        "\n",
        "[De un dialogo de un capitulo de un show animado](https://www.youtube.com/watch?v=us5DJ3el7TM)"
      ],
      "metadata": {
        "id": "OTt10y7ML-zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_audio_file = sr.AudioFile('test_audio.wav')\n",
        "\n",
        "with test_audio_file as source:\n",
        "    test_audio = r.record(source)\n",
        "\n",
        "type(test_audio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "Hsa5gznmMAqw",
        "outputId": "fd88ba1e-ca5c-4793-ee36-28094f635be5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "speech_recognition.audio.AudioData"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>speech_recognition.audio.AudioData</b><br/>def __init__(frame_data, sample_rate, sample_width)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.11/dist-packages/speech_recognition/audio.py</a>Creates a new ``AudioData`` instance, which represents mono audio data.\n",
              "\n",
              "The raw audio data is specified by ``frame_data``, which is a sequence of bytes representing audio samples. This is the frame data structure used by the PCM WAV format.\n",
              "\n",
              "The width of each sample, in bytes, is specified by ``sample_width``. Each group of ``sample_width`` bytes represents a single audio sample.\n",
              "\n",
              "The audio data is assumed to have a sample rate of ``sample_rate`` samples per second (Hertz).\n",
              "\n",
              "Usually, instances of this class are obtained from ``recognizer_instance.record`` or ``recognizer_instance.listen``, or in the callback for ``recognizer_instance.listen_in_background``, rather than instantiating them directly.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 14);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Usamos el api de google para la convesion\n",
        "r.recognize_google(test_audio, language='es-ES')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4enUjZCyRBjK",
        "outputId": "0683c3a5-7f71-4c1a-d712-b400d5ad9b32"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'es el martillo Es real tómenme una fotocopia Oh No hermano'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "Con este ejercicio se demostró que convertir audio a texto no es tan complicado como parece. Usando la librería speech_recognition y un simple archivo .wav, se pudo extraer lo que se decía en el audio con solo unas líneas de código. La herramienta de Google hizo el trabajo pesado, y la transcripción salió bastante bien. Esto puede servir para cosas como analizar audios, hacer subtítulos automáticos o simplemente experimentar con reconocimiento de voz. Lo bueno es que no se necesita saber tanto para que funcione, y eso lo vuelve bastante útil."
      ],
      "metadata": {
        "id": "MyQLdv9eUsxM"
      }
    }
  ]
}